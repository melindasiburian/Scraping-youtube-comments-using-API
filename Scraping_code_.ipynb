{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxPyhOKraolhY70KdDZ8tl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/melindasiburian/Scraping-youtube-comments-using-API/blob/main/Scraping_code_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Q9hujpLwJZoE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "\n",
        "def get_all_replies(comment_id, youtube):\n",
        "    \"\"\"Fetch all replies for a given comment ID, handling pagination.\"\"\"\n",
        "    replies_data = []\n",
        "    response = youtube.comments().list(part='snippet', parentId=comment_id, maxResults=100).execute()\n",
        "\n",
        "    while response:\n",
        "        for reply in response['items']:\n",
        "            reply_published = reply['snippet']['publishedAt']\n",
        "            reply_user = reply['snippet']['authorDisplayName']\n",
        "            reply_text = reply['snippet']['textDisplay']\n",
        "            reply_likeCount = reply['snippet']['likeCount']\n",
        "\n",
        "            # Append each reply to the list\n",
        "            replies_data.append([reply_published, reply_user, reply_text, reply_likeCount, \"Reply\"])\n",
        "\n",
        "        # Check if there is a next page for replies\n",
        "        if 'nextPageToken' in response:\n",
        "            response = youtube.comments().list(part='snippet', parentId=comment_id, pageToken=response['nextPageToken'],\n",
        "                                               maxResults=100).execute()\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return replies_data\n",
        "\n",
        "\n",
        "def video_comments(video_id, api_key):\n",
        "    # List for storing comments and replies\n",
        "    comments_data = []\n",
        "\n",
        "    # Creating youtube resource object\n",
        "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
        "\n",
        "    # Retrieve YouTube video results\n",
        "    video_response = youtube.commentThreads().list(\n",
        "        part='snippet,replies',\n",
        "        videoId=video_id,\n",
        "        maxResults=100\n",
        "    ).execute()\n",
        "\n",
        "    # Iterate over video responses to extract comments and replies\n",
        "    while video_response:\n",
        "\n",
        "        for item in video_response['items']:\n",
        "            # Extracting top-level comment information\n",
        "            top_comment = item['snippet']['topLevelComment']['snippet']\n",
        "            comment_id = item['snippet']['topLevelComment']['id']\n",
        "            published = top_comment['publishedAt']\n",
        "            user = top_comment['authorDisplayName']\n",
        "            comment = top_comment['textDisplay']\n",
        "            likeCount = top_comment['likeCount']\n",
        "\n",
        "            # Append the top-level comment to the list\n",
        "            comments_data.append([published, user, comment, likeCount, \"Comment\"])\n",
        "\n",
        "            # Check for replies to the top-level comment\n",
        "            if 'replies' in item:\n",
        "                # Fetching replies using a separate API call if there are too many\n",
        "                replies_data = get_all_replies(comment_id, youtube)\n",
        "                comments_data.extend(replies_data)\n",
        "\n",
        "        # Pagination: checking if there's a next page of comments\n",
        "        if 'nextPageToken' in video_response:\n",
        "            video_response = youtube.commentThreads().list(\n",
        "                part='snippet,replies',\n",
        "                videoId=video_id,\n",
        "                pageToken=video_response['nextPageToken'],\n",
        "                maxResults=100\n",
        "            ).execute()\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return comments_data\n",
        "\n",
        "\n",
        "# Insert your API key here\n",
        "api_key = \"AIzaSyACNmwdF_Sj8D9Sqdc9PBVAjsaczPNRQRM\"\n",
        "\n",
        "# Video ID example: https://www.youtube.com/watch?v=qwWfBoteiy8\n",
        "video_id = \"qwWfBoteiy8\"\n",
        "\n",
        "# Call function to get comments and replies\n",
        "comments = video_comments(video_id, api_key)\n",
        "\n",
        "# Creating DataFrame from the list of comments and replies\n",
        "df = pd.DataFrame(comments, columns=['publishedAt', 'authorDisplayName', 'textDisplay', 'likeCount', 'Type'])\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv('youtube-comments-with-replies.csv', index=False)"
      ]
    }
  ]
}